{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "Now you know how to build a model with one X (feature variable) and Y (response variable). But what if you have three feature variables, or may be 10 or 100? Building a separate model for each of them, combining them, and then understanding them will be a very difficult and next to impossible task. By using multiple linear regression, you can build models between a response variable and many feature variables.\n",
    "\n",
    "Let's see how to do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step_1 : Importing and Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing advertising.csv\n",
    "advertising_multi = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the first five rows\n",
    "advertising_multi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the last five rows\n",
    "advertising_multi.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What type of values are stored in the columns?\n",
    "advertising_multi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at some statistical information about our dataframe.\n",
    "advertising_multi.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step_2: Visualising Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot a pair plot of all variables in our dataframe\n",
    "\n",
    "#Note: Radio Vs Sales ,Newpaper Vs Sales is  scatter, Radio Vs News is scatter, \n",
    "sns.pairplot(advertising_multi)\n",
    "print(advertising_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the relationship between the features and the response using scatterplots\n",
    "sns.pairplot(advertising_multi, x_vars=['TV','Radio','Newspaper'], y_vars='Sales',size=7, aspect=0.7, kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step_3: Splitting the Data for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting feature variable to X\n",
    "X = advertising_multi[['TV','Radio','Newspaper']]\n",
    "\n",
    "# Putting response variable to y\n",
    "y = advertising_multi['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_state is the seed used by the random number generator. It can be any integer.\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "# TO find oout the Y-prediction we need to test \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7 , random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step_4 : Performing Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representing LinearRegression as lr(Creating LinearRegression Object)\n",
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to the training data\n",
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step_5 : Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the intercept\n",
    "print(lm.intercept_)\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the coefficient\n",
    "#Note : \n",
    "coeff_df = pd.DataFrame(lm.coef_,X_test.columns,columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above result we may infern that if TV price increses by 1 unit it will affect sales by 0.045 units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step_6 : Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the model\n",
    "y_pred = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step_7: Calculating Error Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean_Squared_Error :' ,mse)\n",
    "print('r_square_value :',r_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Step : Checking for P-value Using STATSMODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: This is only for the statics to check the \n",
    "import statsmodels.api as sm\n",
    "X_train_sm = X_train\n",
    "#Unlike SKLearn, statsmodels don't automatically fit a constant, \n",
    "#so you need to use the method sm.add_constant(X) in order to add a constant. \n",
    "#Note add_contract will add the C value i.e Y=Mx+C , is statics we need to manuly tell them to add the constant to the equations\n",
    "# \n",
    "X_train_sm = sm.add_constant(X_train_sm)\n",
    "# create a fitted model in one line\n",
    "# OLS : Ordinary least square =e1+e2+..+en ... \n",
    "lm_1 = sm.OLS(y_train,X_train_sm).fit()\n",
    "\n",
    "# print the coefficients\n",
    "lm_1.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared or R2 explains the degree to which your input variables explain the variation of your output / predicted variable. So, if R-square is 0.8, it means 80% of the variation in the output variable is explained by the input variables. So, in simple terms, higher the R squared, the more variation is explained by your input variables and hence better is your model.\n",
    "\n",
    "However, the problem with R-squared is that it will either stay the same or increase with addition of more variables, even if they do not have any relationship with the output variables. This is where “Adjusted R square” comes to help. Adjusted R-square penalizes you for adding variables which do not improve your existing model.\n",
    "\n",
    "Hence, if you are building Linear regression on multiple variable, it is always suggested that you use Adjusted R-squared to judge goodness of model. In case you only have one input variable, R-square and Adjusted R squared would be exactly same.\n",
    "\n",
    "Typically, the more non-significant variables you add into the model, the gap in R-squared and Adjusted R-squared increases.\n",
    "\n",
    "https://blog.minitab.com/blog/adventures-in-statistics-2/multiple-regession-analysis-use-adjusted-r-squared-and-predicted-r-squared-to-include-the-correct-number-of-variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summery Model will give the statics information \n",
    "#The Below statics report is for trained data not for full data set \n",
    "# From the below report need to under stand the P value ,R square, Adj R square AIC, BIC ,and coefficient values\n",
    "#Gideline to never pass the test data information to out side \n",
    "#Adj-R -Square : Any time while keep on adding varibles to the dataset then Adj R Square will keep on encrease\n",
    "# I need to keep on adjust the Adj R square \n",
    "print(lm_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Newspaper      0.0046      0.008      0.613      0.541      -0.010       0.019 \n",
    "# Newspaper is P value is greater than 50% then we can remove: (0.06 can be removed it is more variables are in the range )\n",
    "#P will be calculate by knowing the Z value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we can see that Newspaper is insignificant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "print(advertising_multi.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " “Covariance” indicates the direction of the linear relationship between variables.\n",
    "“Correlation” on the other hand measures both the strength and direction of the linear relationship between two variables. Correlation is a function of the covariance. \n",
    " it essentially scales the value down to a limited range of -1 to +1. This is precisely the range of the correlation values.\n",
    " The positive sign signifies the direction of the correlation i.e. if one of the variables increases, the other variable is also supposed to increase.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (5,5))\n",
    "sns.heatmap(advertising_multi.corr(),annot = True)\n",
    "#it essentially scales the value down to a limited range of -1 to +1. This is precisely the range of the correlation values.\n",
    "\n",
    "#Note: Black color are not at all considered,  white coloured looks good , grey is looks fine, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step_8 : Implementing the results and running the model again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data above, you can conclude that Newspaper is insignificant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Newspaper from our dataset\n",
    "X_train_new = X_train[['TV','Radio']]\n",
    "X_test_new = X_test[['TV','Radio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building\n",
    "lm.fit(X_train_new,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions\n",
    "y_pred_new = lm.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual vs Predicted\n",
    "c = [i for i in range(1,61,1)]\n",
    "fig = plt.figure()\n",
    "plt.plot(c,y_test, color=\"blue\", linewidth=2.5, linestyle=\"-\")\n",
    "plt.plot(c,y_pred, color=\"red\",  linewidth=2.5, linestyle=\"-\")\n",
    "fig.suptitle('Actual and Predicted', fontsize=20)              # Plot heading \n",
    "plt.xlabel('Index', fontsize=18)                               # X-label\n",
    "plt.ylabel('Sales', fontsize=16)                               # Y-label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error terms\n",
    "c = [i for i in range(1,61,1)]\n",
    "fig = plt.figure()\n",
    "plt.plot(c,y_test-y_pred, color=\"blue\", linewidth=2.5, linestyle=\"-\")\n",
    "fig.suptitle('Error Terms', fontsize=20)              # Plot heading \n",
    "plt.xlabel('Index', fontsize=18)                      # X-label\n",
    "plt.ylabel('ytest-ypred', fontsize=16)                # Y-label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse = mean_squared_error(y_test, y_pred_new)\n",
    "r_squared = r2_score(y_test, y_pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean_Squared_Error :' ,mse)\n",
    "print('r_square_value :',r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = X_train_new\n",
    "#Unlike SKLearn, statsmodels don't automatically fit a constant, \n",
    "#so you need to use the method sm.add_constant(X) in order to add a constant. \n",
    "X_train_final = sm.add_constant(X_train_final)\n",
    "# create a fitted model in one line\n",
    "lm_final = sm.OLS(y_train,X_train_final).fit()\n",
    "\n",
    "print(lm_final.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Refinement Using RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a coef_ attribute or through a feature_importances_ attribute. Then, the less important features are pruned from the the current set of features. This procedure is recursively repeated on the pruned dataset until the desired number of features to select is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rfe = RFE(lm, 2)\n",
    "print(rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression: Newspaper(X) and Sales(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Importing dataset\n",
    "advertising_multi = pd.read_csv('advertising.csv')\n",
    "\n",
    "x_news = advertising_multi['Newspaper']\n",
    "\n",
    "y_news = advertising_multi['Sales']\n",
    "\n",
    "# Data Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_news, y_news, \n",
    "                                                    train_size=0.7 , \n",
    "                                                    random_state=110)\n",
    "\n",
    "# Required only in the case of simple linear regression\n",
    "X_train = X_train[:,np.newaxis]\n",
    "X_test = X_test[:,np.newaxis]\n",
    "\n",
    "# Linear regression from sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "\n",
    "# Fitting the model\n",
    "lm.fit(X_train,y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "# Importing mean square error and r square from sklearn library.\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Computing mean square error and R square value\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "\n",
    "# Printing mean square error and R square value\n",
    "print('Mean_Squared_Error :' ,mse)\n",
    "print('r_square_value :',r_squared)\n",
    "print(lm.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: R_Square : Amount of variance captured by Y from the input variables X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIF : "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
